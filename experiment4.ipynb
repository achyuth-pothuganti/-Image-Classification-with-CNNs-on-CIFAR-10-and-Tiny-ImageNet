{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g5vpDJYUPt4r"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "MJ_x-Z4PRui-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "Y_train = to_categorical(Y_train, 10)\n",
        "Y_test = to_categorical(Y_test, 10)"
      ],
      "metadata": {
        "id": "t4zOeWQ9R0Jr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import model from experiment 3\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "imported_model = load_model('trained_tiny_imagenet_model.h5')\n",
        "\n",
        "imported_model.summary()\n",
        "\n",
        "# Create a new input layer that matches the size of Tiny ImageNet images\n",
        "input_shape = (32, 32, 3)\n",
        "new_input = Input(shape=input_shape)\n",
        "\n",
        "# Pass new_input through the layers of the old model, except for the output layers\n",
        "x = new_input\n",
        "for layer in imported_model.layers[:-3]:  # skip the last three layers (Flatten, Dense, Dense)\n",
        "    x = layer(x)\n",
        "\n",
        "# Calculate the correct output dimensions after the last pooling layer\n",
        "shape_before_flatten = x.shape[1]\n",
        "print(\"Shape before flattening:\", shape_before_flatten)\n",
        "\n",
        "x = Dense(1024, activation='relu', input_shape=(shape_before_flatten,), kernel_regularizer=l2(0.01))(x)  # Adjusted dense layer\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(10, activation='softmax')(x)  # New output layer for 10 classes\n",
        "\n",
        "# Learning rate scheduler function\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 55:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * np.exp(-0.1)\n",
        "\n",
        "# Create new model\n",
        "new_model = Model(inputs=new_input, outputs=x)\n",
        "new_model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci_jEevIR4e_",
        "outputId": "930d8ffe-d1e2-42d8-bb7a-59189efd00ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 64, 64, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 64, 64, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 32, 32, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 32, 32, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              33555456  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200)               205000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34022152 (129.78 MB)\n",
            "Trainable params: 34021384 (129.78 MB)\n",
            "Non-trainable params: 768 (3.00 KB)\n",
            "_________________________________________________________________\n",
            "Shape before flattening: 8192\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " input_2 (InputLayer)        multiple                  0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           multiple                  1792      \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  multiple                  256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           multiple                  36928     \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  multiple                  256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  multiple                  0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         multiple                  0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           multiple                  73856     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  multiple                  512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           multiple                  147584    \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  multiple                  512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  multiple                  0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         multiple                  0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         multiple                  0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              8389632   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8661578 (33.04 MB)\n",
            "Trainable params: 8660810 (33.04 MB)\n",
            "Non-trainable params: 768 (3.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    zoom_range=0.1\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "checkpoint = ModelCheckpoint('exp4_model.keras', save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=10, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "bsaOMrkgaiaD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_schedule = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Compile the new model\n",
        "new_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = new_model.fit(datagen.flow(X_train, Y_train, batch_size=64),\n",
        "                     epochs=200,\n",
        "                     validation_data=(X_test, Y_test),\n",
        "                     callbacks=[early_stopping, checkpoint, lr_schedule])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfCzRMmpa7Vv",
        "outputId": "6fc615e5-e3b9-42be-859f-bf9a2f521173"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "782/782 [==============================] - 30s 35ms/step - loss: 1.3488 - accuracy: 0.6443 - val_loss: 1.3996 - val_accuracy: 0.6122 - lr: 1.0000e-04\n",
            "Epoch 2/200\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 1.2111 - accuracy: 0.6570 - val_loss: 1.2816 - val_accuracy: 0.6226 - lr: 1.0000e-04\n",
            "Epoch 3/200\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 1.1399 - accuracy: 0.6639 - val_loss: 1.1781 - val_accuracy: 0.6459 - lr: 1.0000e-04\n",
            "Epoch 4/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.1060 - accuracy: 0.6706 - val_loss: 1.1970 - val_accuracy: 0.6377 - lr: 1.0000e-04\n",
            "Epoch 5/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0913 - accuracy: 0.6687 - val_loss: 1.2201 - val_accuracy: 0.6255 - lr: 1.0000e-04\n",
            "Epoch 6/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0853 - accuracy: 0.6673 - val_loss: 1.2311 - val_accuracy: 0.6260 - lr: 1.0000e-04\n",
            "Epoch 7/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0749 - accuracy: 0.6717 - val_loss: 1.1784 - val_accuracy: 0.6371 - lr: 1.0000e-04\n",
            "Epoch 8/200\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 1.0726 - accuracy: 0.6716 - val_loss: 1.1741 - val_accuracy: 0.6381 - lr: 1.0000e-04\n",
            "Epoch 9/200\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 1.0598 - accuracy: 0.6725 - val_loss: 1.1687 - val_accuracy: 0.6378 - lr: 1.0000e-04\n",
            "Epoch 10/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0557 - accuracy: 0.6746 - val_loss: 1.2147 - val_accuracy: 0.6239 - lr: 1.0000e-04\n",
            "Epoch 11/200\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 1.0541 - accuracy: 0.6751 - val_loss: 1.1410 - val_accuracy: 0.6469 - lr: 1.0000e-04\n",
            "Epoch 12/200\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 1.0498 - accuracy: 0.6758 - val_loss: 1.1756 - val_accuracy: 0.6366 - lr: 1.0000e-04\n",
            "Epoch 13/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0456 - accuracy: 0.6749 - val_loss: 1.1511 - val_accuracy: 0.6426 - lr: 1.0000e-04\n",
            "Epoch 14/200\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 1.0427 - accuracy: 0.6776 - val_loss: 1.1006 - val_accuracy: 0.6565 - lr: 1.0000e-04\n",
            "Epoch 15/200\n",
            "782/782 [==============================] - 26s 34ms/step - loss: 1.0395 - accuracy: 0.6795 - val_loss: 1.1009 - val_accuracy: 0.6549 - lr: 1.0000e-04\n",
            "Epoch 16/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0412 - accuracy: 0.6811 - val_loss: 1.1326 - val_accuracy: 0.6505 - lr: 1.0000e-04\n",
            "Epoch 17/200\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 1.0400 - accuracy: 0.6778 - val_loss: 1.0660 - val_accuracy: 0.6704 - lr: 1.0000e-04\n",
            "Epoch 18/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0392 - accuracy: 0.6820 - val_loss: 1.1041 - val_accuracy: 0.6574 - lr: 1.0000e-04\n",
            "Epoch 19/200\n",
            "782/782 [==============================] - 26s 34ms/step - loss: 1.0422 - accuracy: 0.6778 - val_loss: 1.1290 - val_accuracy: 0.6541 - lr: 1.0000e-04\n",
            "Epoch 20/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0331 - accuracy: 0.6794 - val_loss: 1.1717 - val_accuracy: 0.6457 - lr: 1.0000e-04\n",
            "Epoch 21/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0331 - accuracy: 0.6825 - val_loss: 1.1369 - val_accuracy: 0.6538 - lr: 1.0000e-04\n",
            "Epoch 22/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0335 - accuracy: 0.6803 - val_loss: 1.1055 - val_accuracy: 0.6624 - lr: 1.0000e-04\n",
            "Epoch 23/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0288 - accuracy: 0.6837 - val_loss: 1.0996 - val_accuracy: 0.6612 - lr: 1.0000e-04\n",
            "Epoch 24/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0354 - accuracy: 0.6815 - val_loss: 1.1449 - val_accuracy: 0.6517 - lr: 1.0000e-04\n",
            "Epoch 25/200\n",
            "782/782 [==============================] - 26s 34ms/step - loss: 1.0347 - accuracy: 0.6802 - val_loss: 1.1742 - val_accuracy: 0.6396 - lr: 1.0000e-04\n",
            "Epoch 26/200\n",
            "782/782 [==============================] - 26s 34ms/step - loss: 1.0257 - accuracy: 0.6844 - val_loss: 1.1274 - val_accuracy: 0.6537 - lr: 1.0000e-04\n",
            "Epoch 27/200\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 1.0298 - accuracy: 0.6832 - val_loss: 1.0616 - val_accuracy: 0.6708 - lr: 1.0000e-04\n",
            "Epoch 28/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0275 - accuracy: 0.6837 - val_loss: 1.0962 - val_accuracy: 0.6648 - lr: 1.0000e-04\n",
            "Epoch 29/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0266 - accuracy: 0.6853 - val_loss: 1.0773 - val_accuracy: 0.6673 - lr: 1.0000e-04\n",
            "Epoch 30/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0241 - accuracy: 0.6855 - val_loss: 1.1598 - val_accuracy: 0.6453 - lr: 1.0000e-04\n",
            "Epoch 31/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0186 - accuracy: 0.6865 - val_loss: 1.1001 - val_accuracy: 0.6638 - lr: 1.0000e-04\n",
            "Epoch 32/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0231 - accuracy: 0.6876 - val_loss: 1.1342 - val_accuracy: 0.6540 - lr: 1.0000e-04\n",
            "Epoch 33/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0201 - accuracy: 0.6878 - val_loss: 1.0801 - val_accuracy: 0.6670 - lr: 1.0000e-04\n",
            "Epoch 34/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0231 - accuracy: 0.6866 - val_loss: 1.1043 - val_accuracy: 0.6633 - lr: 1.0000e-04\n",
            "Epoch 35/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0211 - accuracy: 0.6862 - val_loss: 1.1048 - val_accuracy: 0.6649 - lr: 1.0000e-04\n",
            "Epoch 36/200\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0177 - accuracy: 0.6880 - val_loss: 1.0925 - val_accuracy: 0.6656 - lr: 1.0000e-04\n",
            "Epoch 37/200\n",
            "782/782 [==============================] - ETA: 0s - loss: 1.0194 - accuracy: 0.6890Restoring model weights from the end of the best epoch: 27.\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 1.0194 - accuracy: 0.6890 - val_loss: 1.0987 - val_accuracy: 0.6680 - lr: 1.0000e-04\n",
            "Epoch 37: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_scores = new_model.evaluate(X_test, Y_test, verbose=1)\n",
        "print(f'Model Test accuracy: {model_scores[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEQOVo0Eu4f-",
        "outputId": "7f1507f0-e111-43fc-e445-21c94884ef8c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0616 - accuracy: 0.6708\n",
            "Model Test accuracy: 67.0799970626831%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(history.history).to_csv('exp4_history.csv')"
      ],
      "metadata": {
        "id": "ZesezgICvCYx"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}