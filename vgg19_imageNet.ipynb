{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip IMagenet.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAHKLBxmVjdT",
        "outputId": "e982046e-4ed7-4875-abc5-eebb15a4a58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  IMagenet.zip\n",
            "replace IMagenet/.git/config? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idzF5EJ14duH",
        "outputId": "8f13c794-d514-4718-fa48-c4bc2c87e951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting loading data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-dc7ab3292007>:30: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  train_data += [imageio.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), mode='RGB') for i in range(500)]\n",
            "<ipython-input-13-dc7ab3292007>:37: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  test_data.append(imageio.imread( path + 'val/images/{}'.format(img_name) ,mode='RGB'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished loading data, in 46.45710849761963 seconds\n",
            "train data shape:  (100000, 64, 64, 3)\n",
            "train label shape:  (100000, 200)\n",
            "test data shape:  (10000, 64, 64, 3)\n",
            "test_labels.shape:  (10000, 200)\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "\n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])\n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [imageio.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), mode='RGB') for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data.append(imageio.imread( path + 'val/images/{}'.format(img_name) ,mode='RGB'))\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)\n",
        "\n",
        "train_data, train_labels, test_data, test_labels = get_data(get_id_dictionary())\n",
        "\n",
        "print( \"train data shape: \",  train_data.shape )\n",
        "print( \"train label shape: \", train_labels.shape )\n",
        "print( \"test data shape: \",   test_data.shape )\n",
        "print( \"test_labels.shape: \", test_labels.shape )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_data(train_data, train_labels ):\n",
        "    size = len(train_data)\n",
        "    train_idx = np.arange(size)\n",
        "    np.random.shuffle(train_idx)\n",
        "\n",
        "    return train_data[train_idx], train_labels[train_idx]\n",
        "\n",
        "train_data, train_labels = shuffle_data(train_data, train_labels)"
      ],
      "metadata": {
        "id": "v807T3aSio8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Bnct8zrKB5d"
      },
      "outputs": [],
      "source": [
        "# Keras, dataset, and VGG19 imports\n",
        "import keras\n",
        "from keras.datasets import cifar100, cifar10\n",
        "from keras.applications import VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzgrir8eKNCG",
        "outputId": "f6bb8fd9-859e-45c3-e0f3-97cbec4a4224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 143667240 (548.05 MB)\n",
            "Trainable params: 143667240 (548.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Loading VGG19 with imagenet weights\n",
        "from keras.layers import Input\n",
        "\n",
        "vgg19_model = VGG19(include_top = True, weights='imagenet')\n",
        "vgg19_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORVBKL3ZK9iY",
        "outputId": "c18771ea-dac1-4fbb-ef3d-feffaa5b34a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200)               819400    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 140389640 (535.54 MB)\n",
            "Trainable params: 819400 (3.13 MB)\n",
            "Non-trainable params: 139570240 (532.42 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "\n",
        "# define new empty model\n",
        "model = Sequential()\n",
        "\n",
        "# add all layers except output from VGG19 to new model\n",
        "for layer in vgg19_model.layers[:-1]:\n",
        "  model.add(layer)\n",
        "\n",
        "# freeze all weights\n",
        "for layer in model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# add dropout layer and new output layer\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(200, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf6xMqsALied"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "#(x_train, y_train) , (x_val, y_val) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJK0THJiKBEV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-l6MANqLpZ4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NUM_CLASSES = 200\n",
        "\n",
        "# Onehot encode labels\n",
        "\n",
        "train_labels = keras.utils.to_categorical(train_labels, NUM_CLASSES)\n",
        "test_labels = keras.utils.to_categorical(test_labels, NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JvtmtkbOalx"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhleQ_3SPpcp"
      },
      "outputs": [],
      "source": [
        "# returns batch_size random samples from either training set or validation set\n",
        "# resizes each image to (224, 244, 3), the native input size for VGG19\n",
        "def getBatch(batch_size, train_or_val='train'):\n",
        "  x_batch = []\n",
        "  y_batch = []\n",
        "  if train_or_val == 'train':\n",
        "    idx = np.random.randint(0, len(train_data), (batch_size))\n",
        "\n",
        "    for i in idx:\n",
        "      img = cv2.resize(train_data[i], (224, 224), interpolation=cv2.INTER_CUBIC)\n",
        "      x_batch.append(img)\n",
        "      y_batch.append(train_labels[i] if np.isscalar(train_labels[i]) else train_labels[i][0])\n",
        "  elif train_or_val == 'val':\n",
        "    idx = np.random.randint(0, len(test_data), (batch_size))\n",
        "\n",
        "    for i in idx:\n",
        "      img = cv2.resize(test_data[i], (224, 224), interpolation=cv2.INTER_CUBIC)\n",
        "      x_batch.append(img)\n",
        "      y_batch.append(test_labels[i] if np.isscalar(test_labels[i]) else test_labels[i][0])\n",
        "  else:\n",
        "    print(\"error, please specify train or val\")\n",
        "\n",
        "  x_batch = np.array(x_batch)\n",
        "  y_batch = np.array(y_batch)\n",
        "  #print(x_batch.shape)\n",
        "  #print(y_batch.shape)\n",
        "  return x_batch, y_batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QQfC9F-lnWw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA-GLuGEMMiq",
        "outputId": "ceb8c1a9-32c4-478f-e65c-f0a61bb0c616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Training Loss = 0.35254057401226757\tTraining Acc = 0.95015625\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 0.0011 - categorical_accuracy: 1.0000\n",
            "Validation loss: 0.0010624699061736465\tValidation Acc: 1.0\n",
            "\n",
            "Epoch: 1\n",
            "Training Loss = 0.042299407917744246\tTraining Acc = 0.99296875\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0322 - categorical_accuracy: 0.9900\n",
            "Validation loss: 0.032177481800317764\tValidation Acc: 0.9900000095367432\n",
            "\n",
            "Epoch: 2\n",
            "Training Loss = 0.02629288557334803\tTraining Acc = 0.99265625\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 2.7578e-04 - categorical_accuracy: 1.0000\n",
            "Validation loss: 0.0002757782058324665\tValidation Acc: 1.0\n",
            "\n",
            "Epoch: 3\n",
            "Training Loss = 0.016375793664701634\tTraining Acc = 0.99625\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0183 - categorical_accuracy: 0.9940\n",
            "Validation loss: 0.018314167857170105\tValidation Acc: 0.9940000176429749\n",
            "\n",
            "Epoch: 4\n",
            "Training Loss = 0.030866612774771054\tTraining Acc = 0.99421875\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0202 - categorical_accuracy: 0.9960\n",
            "Validation loss: 0.020182672888040543\tValidation Acc: 0.9959999918937683\n",
            "\n",
            "Epoch: 5\n",
            "Training Loss = 0.0220845567014112\tTraining Acc = 0.99578125\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0397 - categorical_accuracy: 0.9940\n",
            "Validation loss: 0.03969494625926018\tValidation Acc: 0.9940000176429749\n",
            "\n",
            "Epoch: 6\n",
            "Training Loss = 0.033713894347711174\tTraining Acc = 0.9940625\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0022 - categorical_accuracy: 0.9980\n",
            "Validation loss: 0.002224444644525647\tValidation Acc: 0.9980000257492065\n",
            "\n",
            "Epoch: 7\n",
            "Training Loss = 0.02641162378684385\tTraining Acc = 0.994375\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0099 - categorical_accuracy: 0.9960\n",
            "Validation loss: 0.009856253862380981\tValidation Acc: 0.9959999918937683\n",
            "\n",
            "Epoch: 8\n",
            "Training Loss = 0.017921651652141008\tTraining Acc = 0.99625\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 7.0770e-04 - categorical_accuracy: 1.0000\n",
            "Validation loss: 0.0007077032350935042\tValidation Acc: 1.0\n",
            "\n",
            "Epoch: 9\n",
            "Training Loss = 0.02740041434735758\tTraining Acc = 0.99375\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0547 - categorical_accuracy: 0.9880\n",
            "Validation loss: 0.054704152047634125\tValidation Acc: 0.9879999756813049\n",
            "\n",
            "Epoch: 10\n",
            "Training Loss = 0.029789407144562574\tTraining Acc = 0.99359375\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0264 - categorical_accuracy: 0.9940\n",
            "Validation loss: 0.026407767087221146\tValidation Acc: 0.9940000176429749\n",
            "\n",
            "Epoch: 11\n",
            "Training Loss = 0.023762561866778924\tTraining Acc = 0.995\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.1028 - categorical_accuracy: 0.9900\n",
            "Validation loss: 0.10278496146202087\tValidation Acc: 0.9900000095367432\n",
            "\n",
            "Epoch: 12\n",
            "Training Loss = 0.03284310190607357\tTraining Acc = 0.9921875\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0378 - categorical_accuracy: 0.9940\n",
            "Validation loss: 0.037842582911252975\tValidation Acc: 0.9940000176429749\n",
            "\n",
            "Epoch: 13\n",
            "Training Loss = 0.030133497207134496\tTraining Acc = 0.99421875\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0090 - categorical_accuracy: 0.9960\n",
            "Validation loss: 0.009020828641951084\tValidation Acc: 0.9959999918937683\n",
            "\n",
            "Epoch: 14\n",
            "Training Loss = 0.01974205908321892\tTraining Acc = 0.9965625\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0309 - categorical_accuracy: 0.9940\n",
            "Validation loss: 0.030874576419591904\tValidation Acc: 0.9940000176429749\n",
            "\n",
            "Epoch: 15\n",
            "Training Loss = 0.036868714616575746\tTraining Acc = 0.993125\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0412 - categorical_accuracy: 0.9900\n",
            "Validation loss: 0.04124658554792404\tValidation Acc: 0.9900000095367432\n",
            "\n",
            "Epoch: 16\n",
            "Training Loss = 0.030611925698467532\tTraining Acc = 0.995\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0207 - categorical_accuracy: 0.9980\n",
            "Validation loss: 0.020674366503953934\tValidation Acc: 0.9980000257492065\n",
            "\n",
            "Epoch: 17\n",
            "Training Loss = 0.018504005567738204\tTraining Acc = 0.99546875\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0603 - categorical_accuracy: 0.9940\n",
            "Validation loss: 0.06033797189593315\tValidation Acc: 0.9940000176429749\n",
            "\n",
            "Epoch: 18\n",
            "Training Loss = 0.021002203116659075\tTraining Acc = 0.99515625\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0406 - categorical_accuracy: 0.9920\n",
            "Validation loss: 0.0405995175242424\tValidation Acc: 0.9919999837875366\n",
            "\n",
            "Epoch: 19\n",
            "Training Loss = 0.020738312408793716\tTraining Acc = 0.995\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0134 - categorical_accuracy: 0.9980\n",
            "Validation loss: 0.013378890231251717\tValidation Acc: 0.9980000257492065\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "VAL_SIZE = 500\n",
        "STEPS = 50\n",
        "\n",
        "df = pd.DataFrame(columns=['Epoch', 'Training Loss', 'Training Acc', 'Validation Loss', 'Validation Acc'])\n",
        "\n",
        "\n",
        "\n",
        "for e in range(EPOCHS):\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "\n",
        "  for s in range(STEPS):\n",
        "    x_batch, y_batch = getBatch(BATCH_SIZE, \"train\")\n",
        "    out = model.train_on_batch(x_batch, y_batch)\n",
        "    train_loss += out[0]\n",
        "    train_acc += out[1]\n",
        "\n",
        "  print(f\"Epoch: {e}\\nTraining Loss = {train_loss / STEPS}\\tTraining Acc = {train_acc / STEPS}\")\n",
        "\n",
        "  x_v, y_v = getBatch(VAL_SIZE, \"val\")\n",
        "  eval = model.evaluate(x_v, y_v)\n",
        "  print(f\"Validation loss: {eval[0]}\\tValidation Acc: {eval[1]}\\n\")\n",
        "  df.loc[len(df)] = [e, train_loss / STEPS, train_acc / STEPS, eval[0], eval[1]]\n",
        "\n",
        "\n",
        "df.to_csv(\"vgg19_training_history_ImageNet.csv\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLlvvvzHorU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe13c8ea-4b41-4a8d-939d-da18d017f0a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0398 - categorical_accuracy: 0.9940\n",
            "Validation loss: 0.03979633376002312\tValidation Acc: 0.9940000176429749\n",
            "\n"
          ]
        }
      ],
      "source": [
        "x_v, y_v = getBatch(VAL_SIZE, \"val\")\n",
        "eval1 = model.evaluate(x_v, y_v)\n",
        "print(f\"Validation loss: {eval1[0]}\\tValidation Acc: {eval1[1]}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}