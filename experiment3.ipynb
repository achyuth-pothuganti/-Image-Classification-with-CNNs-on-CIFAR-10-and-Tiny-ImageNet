{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTE8_m-SWnue",
        "outputId": "5cfec6fc-bf97-41f7-aa6b-fa451b86b843"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'IMagenet' already exists and is not an empty directory.\n",
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('exp1_best_model.h5')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrP9YpsDHvlA",
        "outputId": "7ec7e6b2-7137-472f-e188-9692fbcd17cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 32, 32, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 8, 8, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              8389632   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8661578 (33.04 MB)\n",
            "Trainable params: 8660810 (33.04 MB)\n",
            "Non-trainable params: 768 (3.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import imageio as nd\n",
        "import numpy as np\n",
        "\n",
        "path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "\n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])\n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [nd.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), mode='RGB') for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data.append(nd.imread( path + 'val/images/{}'.format(img_name) ,mode='RGB'))\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)\n",
        "\n",
        "train_data, train_labels, test_data, test_labels = get_data(get_id_dictionary())\n",
        "\n",
        "print( \"train data shape: \",  train_data.shape )\n",
        "print( \"train label shape: \", train_labels.shape )\n",
        "print( \"test data shape: \",   test_data.shape )\n",
        "print( \"test_labels.shape: \", test_labels.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l68hTG5zLkIE",
        "outputId": "52410747-3968-431c-a991-217bd9cdba8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting loading data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-37e7063e2103>:30: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  train_data += [nd.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), mode='RGB') for i in range(500)]\n",
            "<ipython-input-3-37e7063e2103>:37: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  test_data.append(nd.imread( path + 'val/images/{}'.format(img_name) ,mode='RGB'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished loading data, in 47.607059955596924 seconds\n",
            "train data shape:  (100000, 64, 64, 3)\n",
            "train label shape:  (100000, 200)\n",
            "test data shape:  (10000, 64, 64, 3)\n",
            "test_labels.shape:  (10000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input, Dense, Flatten, Dropout\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "\n",
        "\n",
        "# Assume new input size for Tiny ImageNet\n",
        "new_input = Input(shape=(64, 64, 3))\n",
        "\n",
        "# Create a new input layer that matches the size of Tiny ImageNet images\n",
        "input_shape = (64, 64, 3)\n",
        "new_input = Input(shape=input_shape)\n",
        "\n",
        "model.trainable = True\n",
        "# Pass new_input through the layers of the old model, except for the output layers\n",
        "x = new_input\n",
        "for layer in model.layers[:-3]:  # skip the last three layers (Flatten, Dense, Dense)\n",
        "    x = layer(x)\n",
        "\n",
        "# Calculate the correct output dimensions after the last pooling layer\n",
        "shape_before_flatten = x.shape[1]\n",
        "print(\"Shape before flattening:\", shape_before_flatten)\n",
        "\n",
        "\n",
        "# Flatten and adjust dense layers\n",
        "# x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu', input_shape=(shape_before_flatten,), kernel_regularizer=l2(0.01))(x)  # Adjusted dense layer\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(200, activation='softmax')(x)  # New output layer for 200 classes\n",
        "\n",
        "# Create new model\n",
        "new_model = Model(inputs=new_input, outputs=x)\n",
        "new_model.summary()\n",
        "\n",
        "\n",
        "# Learning rate scheduler function\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 20:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * np.exp(-0.1)\n",
        "\n",
        "# Compile the new model\n",
        "new_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLe76llbK70G",
        "outputId": "83dc4c08-38d0-4009-ebd8-20412f6e3152"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before flattening: 32768\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           multiple                  1792      \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  multiple                  256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           multiple                  36928     \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  multiple                  256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  multiple                  0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         multiple                  0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           multiple                  73856     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  multiple                  512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           multiple                  147584    \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  multiple                  512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  multiple                  0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         multiple                  0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         multiple                  0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              33555456  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200)               205000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34022152 (129.78 MB)\n",
            "Trainable params: 34021384 (129.78 MB)\n",
            "Non-trainable params: 768 (3.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "# Ensure the data is in the correct shape and datatype\n",
        "train_data = train_data.astype('float32')\n",
        "test_data = test_data.astype('float32')\n",
        "\n",
        "# Normalize the data\n",
        "train_data /= 255.0\n",
        "test_data /= 255.0\n",
        "\n",
        "# Verify shapes\n",
        "print(\"Train data shape:\", train_data.shape)\n",
        "print(\"Test data shape:\", test_data.shape)\n",
        "\n",
        "# Create image data generators for data augmentation (optional but recommended)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "# Assuming the model is already compiled from your previous setup\n",
        "# Define batch size and number of epochs\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "# Callback for learning rate adjustment\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Train the model\n",
        "history = new_model.fit(\n",
        "    train_datagen.flow(train_data, train_labels, batch_size=batch_size),\n",
        "    validation_data=test_datagen.flow(test_data, test_labels),\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=len(train_data) // batch_size,\n",
        "    validation_steps=len(test_data) // batch_size,\n",
        "    callbacks=[early_stopping, model_checkpoint, lr_scheduler]\n",
        ")\n",
        "\n",
        "# Optionally, save the trained model\n",
        "new_model.save('trained_tiny_imagenet_model.h5')\n",
        "\n",
        "# Evaluate the model\n",
        "print(new_model.evaluate(test_datagen.flow(test_data, test_labels)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hAsl7JhkXpN",
        "outputId": "a030dda2-72b5-4085-a694-a0900158acce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (100000, 64, 64, 3)\n",
            "Test data shape: (10000, 64, 64, 3)\n",
            "Epoch 1/50\n",
            "1562/1562 [==============================] - ETA: 0s - loss: 6.2265 - accuracy: 0.0368"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1562/1562 [==============================] - 127s 77ms/step - loss: 6.2265 - accuracy: 0.0368 - val_loss: 26.0162 - val_accuracy: 0.0042 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "1562/1562 [==============================] - 121s 78ms/step - loss: 5.9041 - accuracy: 0.0670 - val_loss: 6.7537 - val_accuracy: 0.0373 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "1562/1562 [==============================] - 121s 78ms/step - loss: 5.6787 - accuracy: 0.0865 - val_loss: 5.6714 - val_accuracy: 0.0871 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "1562/1562 [==============================] - 119s 76ms/step - loss: 5.5708 - accuracy: 0.0956 - val_loss: 13.6067 - val_accuracy: 0.0062 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "1562/1562 [==============================] - 120s 77ms/step - loss: 5.4893 - accuracy: 0.1012 - val_loss: 11.2006 - val_accuracy: 0.0122 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "1562/1562 [==============================] - 120s 77ms/step - loss: 5.4400 - accuracy: 0.1050 - val_loss: 8.4337 - val_accuracy: 0.0076 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "1562/1562 [==============================] - 120s 77ms/step - loss: 5.4634 - accuracy: 0.1088 - val_loss: 11.4399 - val_accuracy: 0.0090 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "1562/1562 [==============================] - 121s 78ms/step - loss: 5.4201 - accuracy: 0.1102 - val_loss: 6.7046 - val_accuracy: 0.0300 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "1562/1562 [==============================] - 120s 77ms/step - loss: 5.4090 - accuracy: 0.1121 - val_loss: 23.2148 - val_accuracy: 0.0048 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "1562/1562 [==============================] - 123s 79ms/step - loss: 5.3832 - accuracy: 0.1128 - val_loss: 14.5793 - val_accuracy: 0.0114 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "1562/1562 [==============================] - 120s 77ms/step - loss: 5.3977 - accuracy: 0.1149 - val_loss: 16.1038 - val_accuracy: 0.0070 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "1562/1562 [==============================] - 121s 78ms/step - loss: 5.3734 - accuracy: 0.1178 - val_loss: 14.8682 - val_accuracy: 0.0072 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "1562/1562 [==============================] - 120s 77ms/step - loss: 5.3985 - accuracy: 0.1175 - val_loss: 15.2397 - val_accuracy: 0.0086 - lr: 0.0010\n",
            "Epoch 13: early stopping\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 15.3273 - accuracy: 0.0092\n",
            "[15.327287673950195, 0.009200000204145908]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(history.history).to_csv('trained_tiny_imagenet_history.csv')"
      ],
      "metadata": {
        "id": "tuT3K9BxNIJk"
      },
      "execution_count": 6,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}